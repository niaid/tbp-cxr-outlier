{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "DEPOT_THUMBNAIL_PATH=\"/scratch/tb/thumbnails/\"\n",
    "DCM_PATH=\"/scratch/tb/cxr_hq/\"\n",
    "TEST_PATH=\"/scratch/tb/cxr/\"\n",
    "NUMBER_SAMPLES=500\n",
    "TEST_NUMBER_SAMPLES=NUMBER_SAMPLES\n",
    "RANDOM_SEED=13\n",
    "SAMPLE_IMAGE_SIZE=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import random\n",
    "import functools\n",
    "import multiprocessing\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import SimpleITK as sitk\n",
    "\n",
    "import pandas\n",
    "\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.covariance import EmpiricalCovariance, MinCovDet\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from myshow import myshow\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tbpcxr.utilities import read_dcm, normalize_img\n",
    "import tbpcxr.registration \n",
    "from tbpcxr.model import PCAModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload  \n",
    "reload(tbpcxr.model)\n",
    "reload(tbpcxr.registration)\n",
    "PCAModel = tbpcxr.model.PCAModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two list of image files a *traning* set and a *validation* set. The training set is used to build the PCAModel and the validation set is used to verify that the model is not over fitted at several stages.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_file_list = glob(TEST_PATH+\"/**.dcm\")\n",
    "\n",
    "print( \"Found {0} DICOM.\".format(len(test_file_list)))\n",
    "test_file_list = random.sample(test_file_list, TEST_NUMBER_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seach a directory for files to use\n",
    "#file_list = glob(DEPOT_THUMBNAIL_PATH+\"/**/*thumbnail.png\", recursive=True)\n",
    "#print( \"Found {0} thumbnails.\".format(len(file_list)))\n",
    "\n",
    "# Currently, from one large set of high quality CXR data we are randomly choosing part\n",
    "# for the training and another part for validation.\n",
    "\n",
    "\n",
    "dcm_list = glob(DCM_PATH+\"/**.dcm\")\n",
    "\n",
    "print( \"Found {0} DICOM.\".format(len(dcm_list)))\n",
    "\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "if NUMBER_SAMPLES*2 > len(dcm_list):\n",
    "    print(\"Need to reuse samples for train and validation\")\n",
    "    train_file_list = random.sample(dcm_list, NUMBER_SAMPLES)\n",
    "    validation_file_list = random.sample(dcm_list, NUMBER_SAMPLES)\n",
    "else:\n",
    "    fl = random.sample(dcm_list, NUMBER_SAMPLES*2)\n",
    "    train_file_list = fl[:NUMBER_SAMPLES]\n",
    "    validation_file_list = fl[NUMBER_SAMPLES:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_and_normalize(f):\n",
    "        try:\n",
    "            img = read_dcm(f)\n",
    "        except:\n",
    "            img = sitk.ReadImage(f, sitk.sitkFloat32)\n",
    "            \n",
    "        return normalize_img(img)\n",
    "\n",
    "    \n",
    "def tile_with_scale(image_list, width=10):\n",
    "    img = sitk.Tile([ sitk.RescaleIntensity(img, outputMinimum=0, outputMaximum=255) for img in image_list], [width,0])\n",
    "    return sitk.Cast(img, sitk.sitkUInt8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use multi-processing to read and regularize the data with multiple cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with multiprocessing.Pool() as pool:\n",
    "    train_set = pool.map(read_and_normalize, train_file_list)\n",
    "    validation_set = pool.map(read_and_normalize, validation_file_list)\n",
    "    \n",
    "test_set = list(map(read_and_normalize, test_file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(train_set))\n",
    "tile_width=min(int(sqrt(NUMBER_SAMPLES)), 25)\n",
    "myshow(tile_with_scale(train_set, width=tile_width), title=\"Training Set\")\n",
    "myshow(tile_with_scale(validation_set, width=tile_width), title=\"Validation Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_size_factor=2\n",
    "atlas = tbpcxr.registration.build_atlas(sitk.Expand(pca.image_ref, [atlas_size_factor]*2), train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sitk.WriteImage(atlas, \"cxr_atlas.nrrd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca = PCAModel()\n",
    "pca.image_atlas = sitk.ReadImage(\"cxr_atlas.nrrd\")\n",
    "myshow(pca.image_atlas, title=\"CXR Atlas\")\n",
    "crop_size = crop_size = [int(s * pca.CROP_SIZE/pca.SAMPLE_IMAGE_SIZE) for s in pca.image_atlas.GetSize()]\n",
    "myshow(sitk.Crop(pca.image_atlas, crop_size, crop_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_reg_set = [ pca.register_to_atlas_and_resample(img) for img in train_set ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = sitk.Tile( train_reg_set,  [tile_width,0])\n",
    "imgc = sitk.Tile( [sitk.BinShrink(sitk.Cast(atlas, sitk.sitkFloat32), [atlas_size_factor]*2)]*len(train_reg_set), [tile_width,0])\n",
    "\n",
    "myshow( sitk.Cast(sitk.RescaleIntensity(sitk.Compose(img, img+imgc, img)), sitk.sitkVectorUInt8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reg = pca.register_to_atlas_and_resample(train_set[2], verbose=2)\n",
    "\n",
    "myshow(pca.image_atlas, title=\"CXR Atlas\")\n",
    "\n",
    "myshow(reg, title=\"Registered\")\n",
    "myshow(sitk.Cast(sitk.RescaleIntensity(sitk.Compose(reg, sitk.Resample(pca.image_atlas, reg, outputPixelType=sitk.sitkFloat32), reg)), sitk.sitkVectorUInt8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_reg_set = [ pca.register_to_atlas_and_resample(img) for img in validation_set]\n",
    "myshow(tile_with_scale(validation_reg_set, width=tile_width))\n",
    "sitk.Show(tile_with_scale(validation_reg_set, width=tile_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_reg_set = [ pca.register_to_atlas_and_resample(img) for img in test_set ]\n",
    "myshow(tile_with_scale(test_reg_set, width=tile_width))\n",
    "sitk.Show(tile_with_scale(test_reg_set, width=tile_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of images into a numpy array cropped, for the PCA space\n",
    "train_vec = pca._images_to_arr(train_reg_set)\n",
    "validation_vec = pca._images_to_arr(validation_reg_set)\n",
    "test_vec = pca._images_to_arr(test_reg_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The the PCA computation for a variety of number of components\n",
    "\n",
    "# Compare the residuals of the training data-set to the validation to avoid over fitting the training data\n",
    "mean_res = []\n",
    "min_res = []\n",
    "max_res = []\n",
    "x_res = []\n",
    "validation_res = []\n",
    "\n",
    "for n_component in range(1,min(100,train_vec.shape[0]-1),2):\n",
    "    \n",
    "    pca.compute(train_vec, n_component)\n",
    "    \n",
    "    residuals = pca.residuals(train_vec)\n",
    "    \n",
    "    mean_res.append(np.mean(residuals))\n",
    "    min_res.append(np.min(residuals))\n",
    "    max_res.append(np.max(residuals))\n",
    "    x_res.append(n_component)\n",
    "    \n",
    "    residuals = pca.residuals(validation_vec)\n",
    "    validation_res.append(np.mean(residuals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.fill_between(x_res, max_res, min_res ,  alpha=0.2, label=\"Training Min/Max\")\n",
    "ax.plot(x_res, mean_res, label=\"Training Mean\")\n",
    "ax.plot(x_res, validation_res, label=\"Validation Mean\")\n",
    "ax.set_title(\"PCA Image residuals\")\n",
    "ax.set_xlabel(\"number of components\")\n",
    "ax.set_ylabel(\"RMS residual\")\n",
    "ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "number_of_components=25\n",
    "outlier_dev=6\n",
    "\n",
    "pca = PCAModel()\n",
    "pca.image_atlas = atlas\n",
    "pca.compute(train_vec, 100)\n",
    "\n",
    "\n",
    "# Re-compute PCA dropping the outliers base on Mahalanobis\n",
    "\n",
    "rds = pca.robust_distance(train_vec)\n",
    "rds_threshhold = np.quantile(rds, 0.95)\n",
    "idxs = np.where(rds < rds_threshhold)[0]\n",
    "outlier_idxs = np.where(rds >= rds_threshhold)[0]\n",
    "\n",
    "plt.hist(rds, 128)\n",
    "plt.title(\"Full Training - Mahalanobis\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "res = pca.residuals(train_vec)\n",
    "print(\"Residuals\\n\\tMin: {0}\\n\\tMean: {1}\\n\\tMedian: {2}\\n\\tMax: {3} \".format( np.min(res), np.mean(res), np.median(res), np.max(res)))\n",
    "\n",
    "plt.hist(res, 128)\n",
    "plt.title(\"Full Training -  residuals\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Number of outliers {0}\".format(len(outlier_idxs)))\n",
    "myshow(tile_with_scale([train_reg_set[i] for i in outlier_idxs], 5), title=\"Rejected Registered\")\n",
    "sitk.Show(tile_with_scale([train_set[i] for i in outlier_idxs], 5), title=\"Rejected Original\")\n",
    "\n",
    "\n",
    "train2_vec = train_vec[idxs]\n",
    "\n",
    "\n",
    "pca.compute(train2_vec, number_of_components)\n",
    "\n",
    "res = pca.residuals(train_vec)\n",
    "\n",
    "print(\"Residuals\\n\\tMin: {0}\\n\\tMean: {1}\\n\\tMedian: {2}\\n\\tMax: {3} \".format( np.min(res), np.mean(res), np.median(res), np.max(res)))\n",
    "\n",
    "\n",
    "rds2 = pca.robust_distance(train_vec)\n",
    "outlier_idxs = np.where(rds2 >= rds_threshhold)[0]\n",
    "print(\"Number of outliers {0}\".format(len(outlier_idxs)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.hist(res, 128)\n",
    "plt.title(\"With Outliers Removed\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(pca.residuals(validation_vec), 128)\n",
    "plt.title(\"Test Images\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.image_atlas = atlas\n",
    "pkl_filename = \"cxr_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(pca, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_n = 20\n",
    "res = pca.residuals(train_vec)\n",
    "idxs = np.argsort(res)[-1:-(max_n+1):-1]\n",
    "\n",
    "print(\"res: {}\".format(res[:max_n]))\n",
    "\n",
    "print(\"max res: {}\".format(res[idxs]))\n",
    "\n",
    "\n",
    "print(\"max res: {}\".format(idxs))\n",
    "    \n",
    "sitk.Show(tile_with_scale(train_reg_set[:max_n], 5), title=\"First Images\")\n",
    "sitk.Show(tile_with_scale(pca.restored_images(train_vec[:max_n,:])), title=\"First Image Reconstruction\")\n",
    "\n",
    "sitk.Show(tile_with_scale([train_reg_set[i] for i in idxs], 5) , title=\"Image with Max PCA residuals\")\n",
    "sitk.Show(tile_with_scale([train_set[i] for i in idxs], 5) , title=\"Image with Max PCA residuals\")\n",
    "myshow(tile_with_scale(pca.restored_images(train_vec[idxs,:]), 5), title=\"Image Reconstruction with Max PCA residuals\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comps = pca._arr_to_images(pca.pca.components_)\n",
    "img = tile_with_scale(comps, 5)\n",
    "\n",
    "sitk.WriteImage(img, \"components.png\")\n",
    "myshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "myshow(tile_with_scale(test_reg_set, width=tile_width), title=\"Training Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_res = pca.residuals(train_vec)\n",
    "train_dist = pca.robust_distance(train_vec)\n",
    "\n",
    "\n",
    "validation_res = pca.residuals(validation_vec)\n",
    "validation_dist = pca.robust_distance(validation_vec)\n",
    "\n",
    "\n",
    "test_res = pca.residuals(test_vec)\n",
    "test_dist = pca.robust_distance(test_vec)\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(train_res, train_dist, ls='none', marker='.', label=\"training\", alpha=0.5, markersize=2)\n",
    "\n",
    "plt.plot(validation_res, validation_dist, ls='none', marker='.', label=\"validation\", alpha=0.5, markersize=2)\n",
    "plt.plot(test_res, test_dist, ls='none', marker='.', label=\"testing\", alpha=0.5, markersize=2)\n",
    "plt.xlabel(\"PCA Residuals\")\n",
    "plt.ylabel(\"PCA Mahalanobis Distance\")\n",
    "\n",
    "\n",
    "\n",
    "X = np.stack((train_res, train_dist), axis=-1)\n",
    "train_cov =  MinCovDet().fit(X)\n",
    "\n",
    "\n",
    "X = np.stack((validation_res, validation_dist), axis=-1)\n",
    "validation_cov =  MinCovDet().fit(X)\n",
    "\n",
    "X = np.stack((test_res, test_dist), axis=-1)\n",
    "test_cov =  MinCovDet().fit(X)\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(plt.xlim()[0], plt.xlim()[1], 100),\n",
    "                     np.linspace(plt.ylim()[0], plt.ylim()[1], 100))\n",
    "zz = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "\n",
    "mahal_emp_cov = train_cov.mahalanobis(zz)\n",
    "mahal_emp_cov = mahal_emp_cov.reshape(xx.shape)\n",
    "emp_cov_contour = plt.contour(xx, yy, np.sqrt(mahal_emp_cov))\n",
    "\n",
    "\n",
    "mahal_emp_cov = validation_cov.mahalanobis(zz)\n",
    "mahal_emp_cov = mahal_emp_cov.reshape(xx.shape)\n",
    "emp_cov_contour = plt.contour(xx, yy, np.sqrt(mahal_emp_cov),\n",
    "                                  linestyles='dashed')\n",
    "\n",
    "\n",
    "mahal_emp_cov = test_cov.mahalanobis(zz)\n",
    "mahal_emp_cov = mahal_emp_cov.reshape(xx.shape)\n",
    "emp_cov_contour = plt.contour(xx, yy, np.sqrt(mahal_emp_cov),\n",
    "                                  linestyles='dotted')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2)\n",
    "\n",
    "\n",
    "train_mahalanobis = train_dist\n",
    "\n",
    "axs[0,0].set_title(\"Traning PCA Residuals\")\n",
    "axs[0,0].hist(train_res, 128)\n",
    "axs[0,1].set_title(\"Traning PCA Mahalanobis\")\n",
    "axs[0,1].hist(train_mahalanobis, 128)\n",
    "\n",
    "\n",
    "test_mahalanobis = test_dist\n",
    "\n",
    "axs[1,0].set_title(\"Testing PCA Residuals\")\n",
    "axs[1,0].hist(test_res, 128)\n",
    "axs[1,1].set_title(\"Testing PCA Mahalanobis\")\n",
    "axs[1,1].hist(test_mahalanobis, 128)\n",
    "\n",
    "# the shared labels needs work for this chart\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "#for ax in axs.flat:\n",
    "#    ax.label_outer()\n",
    "\n",
    "print(\"Training PCA Residuals Quantiles: \\n\\t0.50: {0}\\n\\t0.95: {1}\\n\\t0.99: {2}\".\n",
    "     format(np.quantile(train_res, 0.50),\n",
    "            np.quantile(train_res, 0.95),\n",
    "            np.quantile(train_res, 0.99)))\n",
    "print(\"Training Mahalanobis Quantiles: \\n\\t0.50: {0}\\n\\t0.95: {1}\\n\\t0.99: {2}\".\n",
    "     format(np.quantile(train_mahalanobis, 0.50),\n",
    "            np.quantile(train_mahalanobis, 0.95),\n",
    "            np.quantile(train_mahalanobis, 0.99)))\n",
    "\n",
    "threshold_res= np.quantile(train_res, 0.98)\n",
    "threshold_mahalanobis = np.quantile(train_mahalanobis, 0.98)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack((train_res, train_dist), axis=-1)\n",
    "\n",
    "# The construction of the EllipticEnvelope has been moved to the PCAModel.compute method\n",
    "outlier_detector = EllipticEnvelope(contamination=0.10)\n",
    "outlier_detector.fit(X)\n",
    "\n",
    "#X = np.stack((test_res, test_dist), axis=-1)\n",
    "y_pred = outlier_detector.predict(X)\n",
    "\n",
    "\n",
    "\n",
    "# Compare given classifiers under given settings\n",
    "xx, yy = np.meshgrid(np.linspace(0, np.max(X[:,0]), 150),\n",
    "                     np.linspace(0, np.max(X[:,1]), 150))\n",
    "\n",
    "Z = outlier_detector.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='black')\n",
    "\n",
    "colors = np.array(['#377eb8', '#ff7f00'])\n",
    "plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[(y_pred + 1) // 2])\n",
    "plt.xlabel(\"PCA Residuals\")\n",
    "plt.ylabel(\"PCA Mahalanobis Distance\")\n",
    "\n",
    "\n",
    "print(np.count_nonzero(y_pred<0))\n",
    "\n",
    "\n",
    "outliers = np.argwhere(y_pred < 0).flatten()\n",
    "myshow(tile_with_scale([train_set[idx] for idx in outliers], width=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = np.stack((test_res, test_dist), axis=-1)\n",
    "y_pred = outlier_detector.predict(X)\n",
    "\n",
    "\n",
    "\n",
    "# Compare given classifiers under given settings\n",
    "xx, yy = np.meshgrid(np.linspace(0, np.max(X[:,0]), 150),\n",
    "                     np.linspace(0, np.max(X[:,1]), 150))\n",
    "\n",
    "Z = outlier_detector.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='black')\n",
    "\n",
    "colors = np.array(['#377eb8', '#ff7f00'])\n",
    "plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[(y_pred + 1) // 2])\n",
    "\n",
    "\n",
    "outliers = np.argwhere(y_pred < 0).flatten()\n",
    "myshow(tile_with_scale([test_set[idx] for idx in outliers], width=5))\n",
    "sitk.Show(tile_with_scale([test_set[idx] for idx in outliers], width=5))\n",
    "\n",
    "X = np.array( [[test_res[0], test_dist[1]]])\n",
    "y_pred = outlier_detector.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
